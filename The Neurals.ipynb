{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data, drop columns we don't plan to use\n",
    "data = pd.read_csv(\"data/winemag-data-130k-v2.csv\", encoding='utf-8')\n",
    "data.drop([data.columns[0], 'designation', 'taster_twitter_handle'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove special characters, replacing them with their English counterparts. \n",
    "# Transform all text to lower case, remove non letters/whitespace\n",
    "def func(x):\n",
    "    try: \n",
    "        return unidecode.unidecode(x).lower() \n",
    "    except: \n",
    "        return x\n",
    "for col in data.columns:\n",
    "    data[col] = data[col].apply(func)\n",
    "data['description'] = data['description'].apply(lambda x: re.sub(\"[^a-z ]\",\"\", re.sub(\"-\", \" \", x))).apply(lambda x:\n",
    "                                                                                                        '<s> ' + x + ' </s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create output variable(s). Select only top 30 varietals/regions and classify others as 'other'\n",
    "chosen = list(data['variety'].value_counts()[0:30].index)\n",
    "def label_row(row):\n",
    "    if row['variety'] in chosen:\n",
    "        return row['variety']\n",
    "    return 'other'\n",
    "data['y_variety'] = data.apply (lambda row: label_row(row),axis=1)\n",
    "chosen = list(data['province'].value_counts()[0:30].index)\n",
    "def label_row(row):\n",
    "    if row['province'] in chosen:\n",
    "        return row['province']\n",
    "    return 'other'\n",
    "data['y_province'] = data.apply (lambda row: label_row(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate into test and training\n",
    "data = data.drop_duplicates()\n",
    "trainRaw = data.sample(n=100000, replace=False, random_state=1)\n",
    "test_val = data.drop(trainRaw.index)\n",
    "testRaw = test_val.sample(frac=0.5, replace=False, random_state=1)\n",
    "valRaw = test_val.drop(testRaw.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainRaw.to_json(\"train.json\",orient='records')\n",
    "testRaw.to_json(\"test.json\",orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create GloVe matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mittens import GloVe\n",
    "from mittens import Mittens\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "import operator\n",
    "\n",
    "# Reading in data\n",
    "\n",
    "data = pd.read_json('train.json')\n",
    "descriptions = data['description']\n",
    "\n",
    "# Parsing each review\n",
    "\n",
    "reviews = []\n",
    "for d in descriptions:\n",
    "\twords = d.split()\n",
    "\twords.append(\"</s>\")\n",
    "\twords.insert(0, \"<s>\")\n",
    "\treviews.append(words)\n",
    "\n",
    "# Creating vocabulary\n",
    "\n",
    "vocab = {}\n",
    "for r in reviews:\n",
    "\tfor w in r:\n",
    "\t\tif w in vocab:\n",
    "\t\t\tvocab[w] += 1\n",
    "\t\telse:\n",
    "\t\t\tvocab[w] = 1\n",
    "\n",
    "sort = sorted(vocab.items(), key=operator.itemgetter(1), reverse=True)[:5000]\n",
    "top_5k = {}\n",
    "counter = 0\n",
    "for word, _ in sort:\n",
    "\ttop_5k[word] = counter\n",
    "\tcounter += 1\n",
    "\n",
    "np.save('5k_vocab_dict.npy', top_5k) \n",
    "\n",
    "# Initializing co dict\n",
    "\n",
    "co_dict = {}\n",
    "for r in reviews:\n",
    "    for i in range(len(r)):\n",
    "\t\tcurrWord = r[i]\n",
    "\n",
    "\t\tif currWord not in top_5k:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tfor other_i in range(-5, 6):\n",
    "\n",
    "\t\t\tif ((i + other_i) < 0) or ((i + other_i) >= len(r)) or (other_i == 0) or (r[i + other_i] not in top_5k):\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\totherWord = r[i + other_i]\n",
    "\t\t\tdist_weight = 1. / abs(other_i)\n",
    "\n",
    "\t\t\tif other_i < 0:\n",
    "\t\t\t\tif (otherWord, currWord) in co_dict:\n",
    "\t\t\t\t\tco_dict[(otherWord, currWord)] += dist_weight\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tco_dict[(otherWord, currWord)] = dist_weight\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tif (currWord, otherWord) in co_dict:\n",
    "\t\t\t\t\tco_dict[(currWord, otherWord)] += dist_weight\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tco_dict[(currWord, otherWord)] = dist_weight\n",
    "\n",
    "# Creating co-occurance matrix\n",
    "\n",
    "co_matrix = np.zeros((5000, 5000))\n",
    "for word1, word2 in co_dict.keys():\n",
    "    co_matrix[top_5k[word1], top_5k[word2]] = co_dict[(word1, word2)]\n",
    "\n",
    "def glove2dict(glove_filename):\n",
    "    with open(glove_filename) as f:\n",
    "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "        embed = {line[0]: np.array(list(map(float, line[1:])))\n",
    "                for line in reader}\n",
    "    return embed\n",
    "\n",
    "# Training GloVe\n",
    "\n",
    "original_embeddings = glove2dict(\"glove.6B/glove.6B.200d.txt\")\n",
    "vocab_array = vocab.keys()\n",
    "mittens_model = Mittens(n=200, max_iter=2000)\n",
    "new_embeddings = mittens_model.fit(co_matrix, vocab = top_5k.keys(), initial_embedding_dict = original_embeddings)\n",
    "\n",
    "np.save('GloVe_wine_5k.npy', new_embeddings) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load glove matrix and convert to embedding format\n",
    "vectors = np.load(\"data/GloVe_wine_5k.npy\")\n",
    "words = np.load('data/5k_vocab_dict.npy').item()\n",
    "EMBEDDING_DIM = len(vectors[0])\n",
    "embedding_dict = {}\n",
    "for k,v in words.items():\n",
    "    embedding_dict[k] = vectors[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = list(trainRaw['description'])\n",
    "texts_val = list(valRaw['description'])\n",
    "texts_test = list(testRaw['description'])\n",
    "labels = list(trainRaw['y_variety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenize text and pad to make inputs uniform\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_SEQUENCE_LENGTH=136\n",
    "\n",
    "tokenizer = Tokenizer(num_words=len(vectors), filters=[])\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "sequences_val = tokenizer.texts_to_sequences(texts_val)\n",
    "sequences_test = tokenizer.texts_to_sequences(texts_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_val = pad_sequences(sequences_val, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embedding_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert output variable into categorical representation\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(list(trainRaw['y_variety']))\n",
    "labels = le.transform(trainRaw['y_variety'])\n",
    "labels_val = le.transform(valRaw['y_variety'])\n",
    "labels_test = le.transform(testRaw['y_variety'])\n",
    "keys = list(le.classes_)\n",
    "vals = le.transform(keys)\n",
    "labels_index = dict(zip(keys,vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "encoding = to_categorical(labels)\n",
    "encoding_val = to_categorical(labels_val)\n",
    "encoding_test = to_categorical(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "encoding = to_categorical(labels)\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(LSTM(100)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(30, activation='softmax'))\n",
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(data, encoding, epochs=20, verbose=2, validation_data=(data_val_s, encoding_val_s), batch_size=250)\n",
    "model_json = model.to_json()\n",
    "with open(\"model_100_dense.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_100_dense.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model_100_dense.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_100_dense.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 63.64%\n"
     ]
    }
   ],
   "source": [
    "data_val_s = data_val[:-244,]\n",
    "encoding_val_s = encoding_val[:-244,]\n",
    "data_test_s = data_test[:-244,]\n",
    "encoding_test_s = encoding_test[:-244,]\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(data_test_s, encoding_test_s, verbose=0, batch_size=250)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prob = loaded_model.predict(data_test_s, batch_size=250) \n",
    "y_classes = y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'actual')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.imshow(pd.crosstab(y_classes, labels_test[:-244]).apply(lambda r: r/r.sum(), axis=1))\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> produced from vines that are up to  years old this is a firmly structured wine concentration and dry tannins come from some firm extraction the fruit though is ripe and juicy showing red berry flavors along with spice from the wood aging drink the wine from  </s>'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valRaw.iloc[pos]['description'].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bordeaux-style red blend': 0,\n",
       " 'bordeaux-style white blend': 1,\n",
       " 'cabernet franc': 2,\n",
       " 'cabernet sauvignon': 3,\n",
       " 'champagne blend': 4,\n",
       " 'chardonnay': 5,\n",
       " 'gamay': 6,\n",
       " 'gewurztraminer': 7,\n",
       " 'gruner veltliner': 8,\n",
       " 'malbec': 9,\n",
       " 'merlot': 10,\n",
       " 'nebbiolo': 11,\n",
       " 'other': 12,\n",
       " 'pinot grigio': 13,\n",
       " 'pinot gris': 14,\n",
       " 'pinot noir': 15,\n",
       " 'portuguese red': 16,\n",
       " 'portuguese white': 17,\n",
       " 'red blend': 18,\n",
       " 'rhone-style red blend': 19,\n",
       " 'riesling': 20,\n",
       " 'rose': 21,\n",
       " 'sangiovese': 22,\n",
       " 'sauvignon blanc': 23,\n",
       " 'shiraz': 24,\n",
       " 'sparkling blend': 25,\n",
       " 'syrah': 26,\n",
       " 'tempranillo': 27,\n",
       " 'viognier': 28,\n",
       " 'white blend': 29,\n",
       " 'zinfandel': 30}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
